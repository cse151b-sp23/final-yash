{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6a8d86",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dff10c",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://statsandr.com/blog/multiple-linear-regression-made-simple/ (teory for multiple linear regression)\n",
    "- https://machinelearningmastery.com/making-predictions-with-multilinear-regression-in-pytorch/#:~:text=The%20multilinear%20regression%20model%20is,predict%20the%20target%20variable%20y%20. (Implementation Ideologies of multiple Linear Regression)\n",
    "- http://www.sthda.com/english/articles/40-regression-analysis/163-regression-with-categorical-variables-dummy-coding-essentials-in-r/ (Linear Regression using Categorical Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904a7e7",
   "metadata": {},
   "source": [
    "### Rationale For Using this Approach\n",
    "\n",
    "The dataset provides multiple parameters that could be related to the travel duration. This approach generates a linear combination of parameters with weights to generate the output duration thus allowing the use of more than one parameter (as would have been the case for simple linear regression). This will form a baseline machine learning model to evaluate other models used later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016425b6",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed3a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cd9ba",
   "metadata": {},
   "source": [
    "### Read Data and Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3184fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read into Dataframe\n",
    "taxi_data = pd.read_csv(\"kaggle_data/train.csv\")\n",
    "\n",
    "#Calculate and Create Time Column\n",
    "def travel_time(polyline):\n",
    "    return max(polyline.count(\"[\") - 2, 0) * 15\n",
    "\n",
    "def parse_timestamp(taxi_data):\n",
    "    date_time = datetime.fromtimestamp(taxi_data[\"TIMESTAMP\"])\n",
    "    return date_time.year, date_time.month, date_time.day, date_time.hour, date_time.weekday()\n",
    "\n",
    "taxi_data[\"LEN\"] = taxi_data[\"POLYLINE\"].apply(travel_time)\n",
    "\n",
    "taxi_data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = taxi_data[[\"TIMESTAMP\"]].apply(parse_timestamp, axis=1, result_type=\"expand\")\n",
    "\n",
    "mean_duration = taxi_data[\"LEN\"].mean()\n",
    "standard_deviation = taxi_data[\"LEN\"].std()\n",
    "median = taxi_data[\"LEN\"].median()\n",
    "taxi_data = taxi_data[taxi_data[\"LEN\"] < mean_duration + 3*standard_deviation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5fecd",
   "metadata": {},
   "source": [
    "### Input Feature Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92b25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Mapping Call Type Letters to Numbers\n",
    "letter_to_num = {\n",
    "    \"A\" : 1,\n",
    "    \"B\" : 2,\n",
    "    \"C\" : 3\n",
    "}\n",
    "num_to_letter = {\n",
    "    1 : \"A\",\n",
    "    2 : \"B\",\n",
    "    3 : \"C\"\n",
    "}\n",
    "\n",
    "duration = taxi_data[\"LEN\"].tolist()\n",
    "\n",
    "hour = taxi_data[\"HR\"].tolist()\n",
    "month = taxi_data[\"MON\"].tolist() \n",
    "week = taxi_data[\"WK\"].tolist()\n",
    "day = taxi_data[\"DAY\"].tolist()\n",
    "calltype = taxi_data[\"CALL_TYPE\"].tolist()\n",
    "taxi = taxi_data[\"TAXI_ID\"].tolist()\n",
    "\n",
    "for count in range(0, len(calltype), 1):\n",
    "    calltype[count] = (letter_to_num[calltype[count]])   \n",
    "    \n",
    "inputs = []\n",
    "\n",
    "#Combine Input Vectors\n",
    "for count in range(0, len(hour), 1):\n",
    "    inputs.append([hour[count], month[count], week[count], day[count], calltype[count], taxi[count]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4b05b",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4113d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "target = torch.tensor(duration, dtype=torch.float32).to(device)\n",
    "\n",
    "dataset = TensorDataset(inputs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558a828",
   "metadata": {},
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88803ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR(\n",
      "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear2): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (norm): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLR(torch.nn.Module):\n",
    "    # Object Constructor\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_features, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.linear2 = torch.nn.Linear(1, output_features)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.norm = torch.nn.BatchNorm1d(num_features = 6)\n",
    "        \n",
    "    # define the forward function for prediction\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.dropout(self.relu(self.linear(x)))\n",
    "        y_pred = self.dropout(self.relu(self.linear2(x)))\n",
    "        return y_pred\n",
    "    \n",
    "predict = MLR(6, 1)#.to(device)\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e49ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer (this will perform your parameter updates use)\n",
    "lr = 1e-7\n",
    "opt = torch.optim.Adam(predict.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b240ad",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea99491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_err = []\n",
    "parameters = []\n",
    "\n",
    "trainloader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4117cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, optimize):\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in trainloader:\n",
    "            model.train()\n",
    "            prediction = model(x)\n",
    "            loss = torch.sqrt(torch.nn.functional.mse_loss(prediction, torch.unsqueeze(y, 1)))\n",
    "            #print(prediction)\n",
    "            #print(y)\n",
    "            optimize.zero_grad()\n",
    "            loss.backward()\n",
    "            optimize.step()\n",
    "            \n",
    "        print(\"Epoch: \" + str(epoch) + \"\\t\" + \"Loss: \" + str(loss.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153f349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 996.1138305664062\n",
      "Epoch: 1\tLoss: 840.6067504882812\n",
      "Epoch: 2\tLoss: 728.8763427734375\n",
      "Epoch: 3\tLoss: 845.4779052734375\n",
      "Epoch: 4\tLoss: 865.6972045898438\n",
      "Epoch: 5\tLoss: 716.5923461914062\n",
      "Epoch: 6\tLoss: 970.431396484375\n",
      "Epoch: 7\tLoss: 803.6483154296875\n",
      "Epoch: 8\tLoss: 716.9827880859375\n",
      "Epoch: 9\tLoss: 708.0394287109375\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train(epochs, predict, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886f645",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d494e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read into Dataframe\n",
    "test_data = pd.read_csv(\"kaggle_data/test_public.csv\")\n",
    "test_data['ORIGIN_STAND'] = taxi_data['ORIGIN_STAND'].fillna(0)\n",
    "test_data[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = taxi_data[[\"TIMESTAMP\"]].apply(parse_timestamp, axis=1, result_type=\"expand\")\n",
    "\n",
    "test_hour = test_data[\"HR\"].tolist()\n",
    "test_month = test_data[\"MON\"].tolist() \n",
    "test_week = test_data[\"WK\"].tolist()\n",
    "test_day = test_data[\"DAY\"].tolist()\n",
    "test_calltype = test_data[\"CALL_TYPE\"].tolist()\n",
    "test_taxi = test_data[\"TAXI_ID\"].tolist()\n",
    "test_origin = test_data[\"ORIGIN_STAND\"].tolist()\n",
    "\n",
    "for count in range(0, len(test_calltype), 1):\n",
    "    test_calltype[count] = (letter_to_num[test_calltype[count]]) \n",
    "    \n",
    "test_inputs = []\n",
    "for count in range(0, len(test_hour), 1):\n",
    "    test_inputs.append([test_hour[count], test_month[count], test_week[count], test_day[count], test_calltype[count], test_taxi[count]])\n",
    "    \n",
    "test_tensor = torch.tensor(test_inputs, dtype=torch.float32).to(device)\n",
    "\n",
    "test_dataset = TensorDataset(test_tensor)\n",
    "testloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e3866a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1,0.0\n",
      "T2,0.0\n",
      "T3,0.0\n",
      "T4,0.0\n",
      "T5,0.0\n",
      "T6,0.0\n",
      "T7,0.0\n",
      "T8,1.8661231994628906\n",
      "T9,0.0\n",
      "T10,1.4627022743225098\n",
      "T11,0.0\n",
      "T12,0.0\n",
      "T13,1.1850254535675049\n",
      "T14,0.0\n",
      "T15,0.0\n",
      "T16,0.0\n",
      "T17,0.0\n",
      "T18,0.0\n",
      "T19,0.0\n",
      "T20,0.0\n",
      "T21,0.6327923536300659\n",
      "T22,0.0\n",
      "T23,2.746330976486206\n",
      "T24,0.0\n",
      "T25,0.0\n",
      "T26,0.0\n",
      "T27,0.0\n",
      "T28,0.0\n",
      "T29,0.0\n",
      "T30,1.686988115310669\n",
      "T31,0.0\n",
      "T32,0.0\n",
      "T33,0.0\n",
      "T34,0.0\n",
      "T35,0.0\n",
      "T36,0.0\n",
      "T37,0.0\n",
      "T38,0.0\n",
      "T39,0.0\n",
      "T40,0.0\n",
      "T41,0.0\n",
      "T42,0.0\n",
      "T43,0.0\n",
      "T44,0.0\n",
      "T45,0.0\n",
      "T46,0.0\n",
      "T47,0.0\n",
      "T48,0.0\n",
      "T49,0.0\n",
      "T50,3.3593828678131104\n",
      "T51,0.0\n",
      "T52,1.6764670610427856\n",
      "T53,0.0\n",
      "T54,0.004072587005794048\n",
      "T55,2.378579616546631\n",
      "T56,1.9153804779052734\n",
      "T57,0.0\n",
      "T58,0.0\n",
      "T59,0.0\n",
      "T60,0.0\n",
      "T61,3.2462127208709717\n",
      "T62,0.0\n",
      "T63,0.0\n",
      "T64,1.5748587846755981\n",
      "T65,3.1728198528289795\n",
      "T66,0.0\n",
      "T67,0.0\n",
      "T68,0.0\n",
      "T69,0.0\n",
      "T70,0.0\n",
      "T71,0.0\n",
      "T72,0.0\n",
      "T73,0.0\n",
      "T74,0.0\n",
      "T75,0.0\n",
      "T76,0.0\n",
      "T77,0.0\n",
      "T78,0.0\n",
      "T79,0.0\n",
      "T80,0.0\n",
      "T81,1.7906768321990967\n",
      "T82,0.0\n",
      "T83,0.0\n",
      "T84,0.0\n",
      "T85,0.0\n",
      "T86,5.034870147705078\n",
      "T87,0.0\n",
      "T88,0.0\n",
      "T90,0.0\n",
      "T91,4.17775821685791\n",
      "T92,0.0\n",
      "T93,0.0\n",
      "T94,0.0\n",
      "T95,0.0\n",
      "T96,0.0\n",
      "T98,0.0\n",
      "T99,0.0\n",
      "T100,0.0\n",
      "T101,5.032817363739014\n",
      "T102,0.0\n",
      "T103,0.0\n",
      "T104,0.0\n",
      "T107,0.0\n",
      "T109,0.0\n",
      "T110,0.0\n",
      "T111,0.0\n",
      "T112,0.0\n",
      "T113,0.0\n",
      "T114,0.0\n",
      "T115,5.512697696685791\n",
      "T116,0.0\n",
      "T117,0.0\n",
      "T118,0.0\n",
      "T119,4.944796562194824\n",
      "T120,0.0\n",
      "T121,0.9294309020042419\n",
      "T122,0.0\n",
      "T123,0.0\n",
      "T124,0.0\n",
      "T125,0.0\n",
      "T126,0.0\n",
      "T127,2.014962673187256\n",
      "T128,0.0\n",
      "T129,0.0\n",
      "T130,0.0\n",
      "T131,0.0\n",
      "T132,0.0\n",
      "T133,3.7356011867523193\n",
      "T134,0.0\n",
      "T135,0.0\n",
      "T136,0.477792888879776\n",
      "T137,0.0\n",
      "T138,0.0\n",
      "T139,0.0\n",
      "T140,0.0\n",
      "T141,0.6758896112442017\n",
      "T142,0.0\n",
      "T143,0.0\n",
      "T144,4.957370758056641\n",
      "T145,0.0\n",
      "T146,0.0\n",
      "T147,2.5923447608947754\n",
      "T148,5.382846832275391\n",
      "T149,0.0\n",
      "T151,0.0\n",
      "T152,4.402044296264648\n",
      "T153,0.0\n",
      "T154,0.0\n",
      "T155,0.0\n",
      "T156,0.0\n",
      "T157,0.0\n",
      "T158,0.0\n",
      "T159,0.0\n",
      "T160,0.0\n",
      "T161,0.0\n",
      "T162,0.0\n",
      "T163,2.4163029193878174\n",
      "T164,0.0\n",
      "T166,0.0\n",
      "T167,0.0\n",
      "T168,0.0\n",
      "T169,0.0\n",
      "T170,0.0\n",
      "T171,0.0\n",
      "T172,0.0\n",
      "T173,0.0\n",
      "T174,0.0\n",
      "T175,0.0\n",
      "T176,0.0\n",
      "T177,0.0\n",
      "T178,0.0\n",
      "T179,0.0\n",
      "T180,0.0\n",
      "T181,0.0\n",
      "T182,0.0\n",
      "T183,0.0\n",
      "T184,0.0\n",
      "T185,4.638904571533203\n",
      "T186,0.0\n",
      "T187,0.0\n",
      "T188,0.7020785808563232\n",
      "T189,0.481899619102478\n",
      "T190,1.6105284690856934\n",
      "T191,0.0\n",
      "T192,0.0\n",
      "T193,0.0\n",
      "T194,0.0\n",
      "T195,0.0\n",
      "T196,0.0\n",
      "T197,0.0\n",
      "T198,0.0\n",
      "T199,3.0912137031555176\n",
      "T200,0.0\n",
      "T201,0.0\n",
      "T202,0.0\n",
      "T203,0.0\n",
      "T204,0.0\n",
      "T205,0.0\n",
      "T206,0.0\n",
      "T207,0.0\n",
      "T208,0.0\n",
      "T209,0.0\n",
      "T210,0.0\n",
      "T211,0.0\n",
      "T212,0.0\n",
      "T213,0.0\n",
      "T214,0.0\n",
      "T215,0.0\n",
      "T216,0.0\n",
      "T217,0.0\n",
      "T218,0.8026736974716187\n",
      "T219,0.0\n",
      "T220,0.0\n",
      "T221,0.0\n",
      "T222,0.0\n",
      "T223,0.0\n",
      "T224,0.0\n",
      "T225,0.0\n",
      "T226,0.0\n",
      "T227,0.0\n",
      "T228,0.0\n",
      "T229,0.0\n",
      "T230,0.0\n",
      "T231,0.0\n",
      "T232,0.0\n",
      "T233,2.4414517879486084\n",
      "T234,0.0\n",
      "T235,2.8281912803649902\n",
      "T236,0.0\n",
      "T237,0.0\n",
      "T238,0.0\n",
      "T239,0.0\n",
      "T240,0.0\n",
      "T241,0.0\n",
      "T242,0.0\n",
      "T243,0.0\n",
      "T244,0.0\n",
      "T245,1.0405468940734863\n",
      "T246,0.0\n",
      "T247,0.0\n",
      "T248,0.0\n",
      "T249,0.0\n",
      "T250,0.0\n",
      "T251,0.0\n",
      "T252,0.0\n",
      "T253,0.0\n",
      "T254,0.0\n",
      "T255,0.0\n",
      "T256,0.0\n",
      "T257,0.8906944990158081\n",
      "T258,0.0\n",
      "T259,0.0\n",
      "T260,0.0\n",
      "T261,0.0\n",
      "T262,0.0\n",
      "T263,0.0\n",
      "T264,0.0\n",
      "T265,0.0\n",
      "T266,0.0\n",
      "T267,0.0\n",
      "T268,0.0\n",
      "T269,0.0\n",
      "T270,0.0\n",
      "T271,0.0\n",
      "T272,0.0\n",
      "T273,0.0\n",
      "T274,0.0\n",
      "T275,0.0\n",
      "T276,0.0\n",
      "T277,0.0\n",
      "T278,0.0\n",
      "T279,0.0\n",
      "T280,0.0\n",
      "T281,0.0\n",
      "T282,0.0\n",
      "T283,0.0\n",
      "T284,0.19910281896591187\n",
      "T285,0.0\n",
      "T286,0.5229436755180359\n",
      "T287,0.0\n",
      "T288,0.0\n",
      "T289,0.0\n",
      "T290,0.0\n",
      "T291,0.0\n",
      "T292,0.0\n",
      "T293,0.0\n",
      "T294,0.0\n",
      "T295,0.0\n",
      "T296,0.0\n",
      "T297,0.2735089361667633\n",
      "T298,2.422717332839966\n",
      "T299,0.0\n",
      "T300,5.328442573547363\n",
      "T301,0.5208902955055237\n",
      "T302,2.8261382579803467\n",
      "T303,0.0\n",
      "T304,0.0\n",
      "T305,1.4041913747787476\n",
      "T306,0.0\n",
      "T307,0.0\n",
      "T308,0.0\n",
      "T309,0.0\n",
      "T310,0.0\n",
      "T311,0.0\n",
      "T312,2.1093978881835938\n",
      "T313,0.0\n",
      "T314,0.0\n",
      "T315,0.0\n",
      "T316,0.0\n",
      "T317,0.0\n",
      "T318,0.0\n",
      "T319,3.894961357116699\n",
      "T320,2.2371950149536133\n",
      "T321,0.0\n",
      "T322,0.0\n",
      "T323,2.924679756164551\n",
      "T324,0.0\n",
      "T325,0.0\n",
      "T326,0.0\n",
      "T327,0.0\n"
     ]
    }
   ],
   "source": [
    "test_ids = test_data[\"TRIP_ID\"].tolist()\n",
    "\n",
    "prediction = predict(test_tensor)\n",
    "    #loss = torch.sqrt(torch.nn.functional.mse_loss(prediction, torch.unsqueeze(y, 1)))\n",
    "    #optimize.zero_grad()\n",
    "    #loss.backward()\n",
    "    #optimize.step()\n",
    "prediction = prediction.tolist()\n",
    "    \n",
    "for i in range (0, len(test_ids), 1):\n",
    "    print(str(test_ids[i])+\",\"+str(prediction[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242d262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
